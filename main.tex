\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{ntheorem}
\usepackage{mdframed}
\usepackage{tikz} 
\usepackage{enumitem}
\title{\Huge TTK4215 - Study Sheet}
\author{Halvor TÃ¸fte Johnsen}
\date{20.10.2023}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }

\theoremseparator{}
\newmdtheoremenv[
    skipabove=10pt,
    skipbelow=10pt,
    linecolor=black,
    backgroundcolor=gray!10,
    roundcorner=5pt,
]{frm-ex}{Example}

\theoremseparator{}
\newmdtheoremenv[
    skipabove=10pt,
    skipbelow=10pt,
    linecolor=black,
    backgroundcolor=gray!10,
    roundcorner=5pt,
]{frm-prf}{Proof}


\begin{document}
\maketitle
\begin{multicols*}{2}
\section{Important Definitions}
\subsection{Norm}
The norm $|x|$ of a vector $x$ is a real valued function with the following properties:
\begin{enumerate}[label=(\roman*)]
	\item $|x| \geq 0$ with $|x|=0$ if and only if $x=0$
	\item $|\alpha x|=|\alpha| x \mid$ for any scalar $\alpha$
	\item $|x+y| \leq|x|+|y|$ (triangle inequality)
\end{enumerate}
The norm $|x|$ of a vector $x$ can be thought of as the size or length of the vector $x$. Similarly, $|x-y|$ can be thought of as the distance between the vectors $x$ and $y$.
\subsection{Induced Norm}
Let $|\cdot|$ be a given vector norm. Then for each matrix $A \in \mathcal{R}^{m \times n}$, the quantity $\|A\|$ defined by
\(
\|A\| \triangleq \sup _{\substack{x \neq 0 \\ x \in \mathcal{R}^n}} \frac{|A x|}{|x|}=\sup _{|x| \leq 1}|A x|=\sup _{|x|=1}|A x|
\)
is called the induced (matrix) norm of $A$ corresponding to the vector norm $|\cdot|$.
\\\\
Some of the properties of the induced norm that we will often use in this book are summarized as follows:
\begin{enumerate}[label=(\roman*)]
	\item $|A x| \leq\|A\||x|, \quad \forall x \in \mathcal{R}^n$
	\item $\|A+B\| \leq\|A\|+\|B\|$
	\item $\|A B\| \leq\|A\|\|B\|$
\end{enumerate}
\subsection{$\mathcal{L}_p$ spaces}
for functions fo time, we define the $\mathcal{L}_p$ norm
\begin{equation*}
	\|x\|_p \triangleq\left(\int_0^{\infty}|x(\tau)|^p d \tau\right)^{1 / p}
\end{equation*}
for $p \in[1, \infty)$ and say that $x \in \mathcal{L}_p$ when $\|x\|_p$ exists (i.e., when $\|x\|_p$ is finite). The $\mathcal{L}_{\infty}$ norm is defined as
$$
	\|x\|_{\infty} \triangleq \sup _{t \geq 0}|x(t)|
$$
and we say that $x \in \mathcal{L}_{\infty}$ when $\|x\|_{\infty}$ exists.
In the above $\mathcal{L}_p, \mathcal{L}_{\infty}$ norm definitions, $x(t)$ can be a scalar or a vector function. If $x$ is a scalar function, then $|\cdot|$ denotes the absolute value. If $x$ is a vector function in $\mathcal{R}^n$ then $|\cdot|$ denotes any norm in $\mathcal{R}^n$.
\begin{frm-ex}[$\mathcal{L}_p$ spaces]
Consider the function $f(t)=\frac{1}{1+t}$. Then,
$$
	\begin{gathered}
		\|f\|_{\infty}=\sup _{t \geq 0}\left|\frac{1}{1+t}\right|=1, \quad\|f\|_2=1
	\end{gathered}
$$
Hence, $f \in \mathcal{L}_2 \bigcap \mathcal{L}_{\infty}$ but $f \notin \mathcal{L}_1 ; f$, however, belongs to $\mathcal{L}_{1 e}$, i.e., for any finite $t \geq 0$, we have
$$
	\int_0^t \frac{1}{1+\tau} d \tau=\ln (1+t)<\infty
$$
\end{frm-ex}
\begin{itemize}
	\item A function $f$ belongs to $L^1$ if the integral of the absolute value of $f$ over its entire domain is finite. Mathematically, this can be expressed as:
	      \[ \int |f(x)| \, dx < \infty \]
	      In $L^1$, functions are required to have a finite "$\mathcal{L}_1$  norm."
	\item  A function $f$ belongs to $L^2$ if the square of the absolute value of $f$ is Lebesgue integrable, meaning:
	      \[ \int |f(x)|^2 \, dx < \infty \]
	      In $L^2$, functions are required to have a finite "L norm."
	\item A function $f$ belongs to $L^\infty$ if it is bounded, meaning there exists a constant $M$ such that $|f(x)| \leq M$ for all $x$. In $L^\infty$, functions are required to have a finite "norm," which is essentially the supremum (maximum) of the absolute value of the function.
\end{itemize}
\subsection{Persistence of Excitation and Sufficiently Rich Inputs}
The vector $\phi \in \mathcal{R}^n$ is \textbf{persitently exciting (PE)} with level $\alpha_0$ if it for all $t \geq 0$ satisfies
\begin{equation*}.
	\int_{t}^{t+T_0}\phi(\tau)\phi^T(\tau)d\tau \geq \alpha_0 T_0 I
\end{equation*}

for some $\alpha_0 > 0$ and \(T_0 > 0\). I.e, in control theory, a system is said to be persistently exciting if its input signal is rich enough to excite all the modes of the system for a sufficiently long time. In other words, the input signal should be diverse enough to cover the entire range of the system's behavior.The benefit of having a persistently exciting input signal is that it allows us to accurately estimate the parameters of the system. This is because a rich input signal provides more information about the system's behavior, which in turn allows us to better estimate its parameters.
\section{Parameter Identification: Continuous Time}
A simple static parametric model (SPM) is given by
\begin{equation}
	z(t) = \theta^{*}\phi(t)
\end{equation}
where $\theta^{*}$ is the unknown parameters
\subsection{Estimation Model and Estimation Error}
The SPM model with an estimate of the the unknown parameter $\theta^{*}$ is replaced with its estimate at time $t$
\begin{equation}
	\hat{z}(t) = \theta(t)\phi(t)
\end{equation}
We can further introduce $\tilde{\theta}$ as $\tilde{\theta}=\theta(t)-\theta^*$, but is \textbf{NOT} available for measurments. We can further introduce the \textbf{estimation error} as
\begin{equation}
	\epsilon = \frac{z - \hat{z}}{m_s ^2}
\end{equation}
where $m_s^2 > 0$ as the normalizing signal, which is needed if $\phi \in \mathcal{L}_{\infty}$, i.e. it is used to estblish boundedness of the estimated parametes even when $\phi$ is not guaranteed to be boundend. Often $m_s^2$ is choosen as $m_s^2=1+\alpha \phi^2, \; \alpha > 0$. Further the estimation error can be written as
\begin{equation}
	\epsilon = - \frac{\tilde{\theta}\phi(t)}{m_s ^2}
\end{equation}
A simple adamptive law can therefore as
\begin{equation}
	\dot \theta = \gamma \epsilon \phi, \qquad \theta(0) = \theta_0
\end{equation}
\subsection{Gradient Algorithm with Instentaneous Cost Function}
The adaptive law for a gradient algorithm with instentaneous cost function is
\begin{equation}
	\dot \theta = - \Gamma \epsilon \phi
\end{equation}
where $\Gamma$ is a positive definite matrix, $\Gamma > 0$
\textit{
	The gradient algorithm with instentaneous cost function guarantees
	\begin{enumerate}[label = (\roman*)]
		\item $\epsilon, \epsilon m, \dot \epsilon \in \mathcal{L}_2 \; \cap \; \mathcal{L}_{\infty}$ and $\theta \in \mathcal{L}_{\infty}$
		\item If $\frac{\phi}{m_s}$ is PE, i.e. $\int_{t}^{t+T_0}\frac{\phi \phi^T}{m_s^2} d \tau > \alpha_0 T_0 I \forall t \geq 0$ and for some $T_0, \alpha_0 > 0$, then $\theta(t) \to \theta^*$ exponentially fast.
	\end{enumerate}}
Further we can choose a a Lyapunov-like functions to analyze the stability of the system
\begin{equation*}
	V(\tilde{\theta}) = \frac{\tilde{\theta^T \Gamma^{-1} \tilde{\theta}}}{2}
\end{equation*}
We can derive $\dot V$ as
\begin{equation*}
	\dot V = \tilde{\theta^T} \phi \epsilon = - \epsilon ^2 m_s ^2 \leq 0
\end{equation*}
We see that $\Gamma > 0$ and $\dot V \leq 0$, and it follows that
\begin{equation*}
	\lim_{t \to \infty} V(\tilde{\theta(t)}) = V_{\infty} \leq \infty
\end{equation*}
\begin{frm-ex}[]
\item
Consider the nonlinear system
\begin{equation*}
	\dot x = a f(x) + b g(x)u,
\end{equation*}
where $a$ and $b$ are unknown constants, $f(x)$, $g(x)$ are known continous functions of $x$, and $x, \; u$ are available for measurment. We want to estimate $a, b$ online. We first obtain a parametric model in the form of an SPM by filtering each side with $\frac{q}{\Lambda(s)}\frac{1}{s+\lambda}$ for some $\lambda > 0$.
\begin{equation*}
	\frac{s}{s+\lambda}x = a \frac{1}{s+ \lambda}f(x) + b \frac{1}{s+\lambda}g(x)u
\end{equation*}
Then, for
\begin{equation*}
	z = \frac{s}{s+\lambda}x, \qquad \theta = [a,b]^T, \qquad \phi = \frac{1}{s+\lambda}[f(x), g(x)u]^T,
\end{equation*}
we
\end{frm-ex}
\section{Model Reference Adaptive Control}
Model reference adaptive control is a control method that uses a mathematical model of the dynamic system to be controlled to produce control signals that cause the model to behave in a way which is "similar" to the actual system. The control algorithm then uses the difference between the model output and the actual system output to adapt the model to the actual system.
\begin{itemize}
	\item \textbf{Indirect adaptive control} Parameters are estimeated and then used in a controller.
	\item \textbf{Direct adaptive control} Parameterize the closed loop in therms of the controller parameters, and develop an adaptive law for the controller parameters directly
\end{itemize}
\subsection{Indirect MRAC without normalization}
We have the following scalar system
\begin{equation*}
	\dot x = a x(t) + b u(t)
\end{equation*}
and the following reference model
\begin{equation*}
	\dot x_m (t) = -a_m x_m(t) + b_m r(t)
\end{equation*}
where $a_m > 0$  and $r(t) \in  \mathcal{L}{\infty}$ is the reference signal. From these two equations we can derive the following model reference control law
\begin{equation*}
	u(t) = \frac{1}{b}(-a x(t) - a_m x(t) + b_m r(t))
\end{equation*}
Further we do \textbf{NOT} know $a_m$ and $b_m$, but we can estimate them as $\hat{a}$ and $\hat{b}$. Further we have the new adaptive law
\begin{equation*}
	u(t) = \frac{1}{\hat{b}}(- \hat{a} x(t) - a_m x(t) + b_m r(t))
\end{equation*}
The problem is then to find adaptive laws for $\hat{a}$ and $\hat{b}$ so $x$ tracks $x_m$ asymptotically. We can define the following tracking error $e(t) = x(t) - x_m(t)$ and its derivative
\begin{equation*}
	\dot e(t) = -a_m e + a_m x + a_x + \hat{b} r(t) u - b_m r . \tilde{b} u
\end{equation*}
where $\tilde{b} = b - \hat{b}$. We can further insert $u$ in the tracking error and get the following
\begin{equation*}
	\dot e(t) = -a_m e - \tilde{a} x - \tilde{b}u
\end{equation*}
This form allows us to design adaptive laws for $\hat{a}$ and $\hat{b}$ using the Lyapunov function candidate
\begin{equation*}
	V = \frac{1}{2} e^2 + \frac{1}{2} \tilde{a}^2 + \frac{1}{2} \tilde{b}^2
\end{equation*}
where $\gamma_i > 0$. We can then derive the following adaptive laws
\begin{equation*}
	\dot V = -a_m e ^2 + \frac{1}{\gamma_1} \tilde{a} (\dot{\hat{a}} - \gamma_1 x e) + \frac{1}{\gamma_2} \tilde{b} (\dot{\hat{b}} - \gamma_2 u e)
\end{equation*}
where $(\dot{\hat{a} - \gamma_1 x e}) = 0$ gives the adaptive law for $\hat{a} $ and $(\dot{\hat{b}} - \gamma_2 u e) = 0$ gives the adaptive law for $\hat{b}$. I.e.
\begin{equation*}
	\begin{split}
		\dot{\hat{a}} & = \gamma_1 x e \\
		\dot{\hat{b}} & = \gamma_2 u e
	\end{split}
\end{equation*}
We obtain
\begin{equation*}
	\dot V = -a_m e ^2
\end{equation*}
It follows that $\hat{a}, \hat{b} \in \mathcal{L}_{\infty}$ and $e \in \mathcal{L}_{\infty} \cap \mathcal{L}_2$. Therefore, if we can establish that $\dot{e} \in \mathcal{L}_{\infty}$, we can use Barbarlat's lemma to conclude that $e \rightarrow 0$, which is equivalent to $x \rightarrow x_m$. Since $r \in$ $\mathcal{L}_{\infty}$, it follows that $x_m \in \mathcal{L}_{\infty}$, and in turn that $x \in \mathcal{L}_{\infty}$. Why? So from (7) we have $\dot{e} \in \mathcal{L}_{\infty}$ provided $u \in \mathcal{L}_{\infty}$.  If the estimate $\hat{b}$ approaches $0, u$ may grow unbounded. We have excluded $b=0$ to guarantee that (2) is controllable, so we should also exclude the possibility for $\hat{b}$ to cross zero. This can be done if we assume that we know the sign of $b$ and have a lower bound for $|b|$, that is $|b| \geq b_0>0$. Then, (11) can be modified to
$$
	\dot{\hat{b}}= \begin{cases}\gamma_2 u e, & \text { if } \operatorname{sign}(b) u e>0 \text { or }|\hat{b}|>b_0 \\ 0, & \text { otherwise }\end{cases}
$$
The control law can be written
$$
	u(t)=-k(t) x(t)+l(t) r(t)
$$
with
$$
	\begin{aligned}
		k(t) & =\frac{\hat{a}(t)+a_m}{\hat{b}(t)} \\
		l(t) & =\frac{b_m}{\hat{b}(t)} .
	\end{aligned}
$$
The fact that the controller parameters $k(t)$ and $l(t)$ are computed based on estimates of the plant parameters $\hat{a}(t)$ and $\hat{b}(t)$ makes the adaptive control indirect.
\subsection{Direct MRAC without normalization}
The ideal model reference control can be written as
\begin{equation*}
	u(t) = - k ^* x(t) + l ^* r (t)
\end{equation*}
where
\begin{equation*}
	\begin{split}
		k ^* = \frac{a_m + a}{b} \\
		l ^* = \frac{b_m}{b}
	\end{split}
\end{equation*}
The dynamics of the tracking error $e$ can now be manipulated as
\begin{equation*}
	\dot = - a_m e + b (k ^* - l ^* r 0 u)
\end{equation*}
Now we let
\begin{equation*}
	u = -k(t) x + l(t) r
\end{equation*}
be subsituted into $\dot e$ and we get
\begin{equation*}
	\dot e = - a_m e + b (\tilde{k}x + \tilde{l} r)
\end{equation*}
where $\tilde{k}= k - k ^*$ and $\tilde{l}= l - l ^*$
We then select the Lyapunov function candidate
\begin{equation*}
	V = \frac{1}{2} e^2 + \frac{1}{2} \tilde{a}^2 + \frac{1}{2} \tilde{b}^2
\end{equation*}
where $\gamma_i > 0$. We can then derive the following adaptive laws
\begin{equation*}
	\dot V = -a_m e ^2 + \frac{1}{\gamma_1} \tilde{k} (\dot{k} - \gamma_1 b e x) + \frac{1}{\gamma_2} \tilde{l} (\dot{\l} + \gamma_2b e r)
\end{equation*}
where the adaptive laws are
\begin{equation*}
	\begin{split}
		\dot k(t) & = \gamma_1 b e(t) x(t)   \\
		\dot l(t) & = - \gamma_2 b e(t) r(t)
	\end{split}
\end{equation*}
These adaptive laws have a problem $b$ appears, which is uncertain. This can be fixed by assuming we know the signe of $b$. $\gamma_i>0$ then the adaptive laws can be scaled by any positive factor, and we therefore divide by $|b| > 0$ to obtain
\begin{equation*}
	\begin{split}
		\dot k(t) & = \gamma_1 \frac{b}{|b|} e(t) x(t)   \\
		\dot l(t) & = - \gamma_2 \frac{b}{|b|} e(t) r(t)
	\end{split}
\end{equation*}
Since $\frac{b}{|b|}= sign(b)$ we get
\begin{equation*}
	\begin{split}
		\dot k(t) & = \gamma_1 sign(b) e(t) x(t)   \\
		\dot l(t) & = - \gamma_2 sign(b) e(t) r(t)
	\end{split}
\end{equation*}
Rest of the analysis is similar to the indirect MRAC
\subsection{Indirect MRAC with normalization}
We consider the same system
\begin{equation*}
	\dot x(t) = a x(t) + b u(t)
\end{equation*}
where $a$ and $b$ are unknown. We also consider the same reference model
\begin{equation*}
	\dot x_m(t) = -a_m x_m(t) + b_m r(t)
\end{equation*}
and we wnat $x$ to track $x_m$. From the \textit{Indirect MRAC without normalization} we have the following MRAC scheme
\begin{equation*}
	\begin{split}
		u(t) & = -k(t) x(t) + l(t) r(t)              \\
		k(t) & = \frac{a_m + \hat{a}(t)}{\hat{b}(t)} \\
		l(t) & = \frac{b_m}{\hat{b}(t)}
	\end{split}
\end{equation*}
We assume that the sign of $b$ and the lower bound $b_0$ for $|b|$ are known. We also assume that $b_m \neq 0$ and $b \neq 0$. $a$ and $b$ satisfies the SPM
\begin{equation*}
	\begin{split}
		z         & = \theta^T \phi                  \\
		z         & = \frac{s}{s + \lambda} x        \\
		\theta ^* & = [a, b]^T                       \\
		\phi      & = \frac{1}{s + \lambda} [x, u]^T
	\end{split}
\end{equation*}
The normalized parameter estimation error is
\begin{equation*}
	\epsilon = \frac{z - \theta ^T \phi}{m_s ^2}
\end{equation*}
where $\theta = [\hat{a}, \hat{b}] ^T$ and $m_s$ guarantees that $\frac{\phi}{m_s} in \mathcal{L}_{\infty}$. We can further choose our method as long as it has the desiered properties. \textbf{The key to show that with any of the adaptive laws with normalization achives $x \to x_m$ is to show that $x$ is bounded.}
\subsection{Direct MRAC with normalization}
In the direct MRAC case, we need to parameterize the system in terms of the controller parameters. We have already done this in (20) which is equivalent to
$$
	e=\frac{b}{s+a_m}\left[u+k^* x-l^* r\right] .
$$

We can further rewrite (51) as the B-SPM
$$
	e=b\left(\theta^{*^T} \phi+u_f\right)
$$
where
$$
	\begin{aligned}
		\theta^* & =\left[k^*, l^*\right]^T, \\
		\phi     & =\frac{1}{s+a_m}[x,-r]^T, \\
		u_f      & =\frac{1}{s+a_m}[u] .
	\end{aligned}
$$
It can be shown that system (31) in closed loop with the control law
$$
	u(t)=-k(t) x(t)+l(t) r(t)
$$
where $k(t)$ and $l(t)$ are estimates of $k^*$ and $l^*$ obtained from an adaptive law with normalization based on the parameterization (52) will achieve boundedness of all signals and tracking $x \rightarrow x_m$. The proof is similar to the indirect case, and the key is to prove boundedness of all signals from which tracking follows quite straight forwardly from the properties of the adaptive law. The interested student is referred to the book for details.
\section{Robustness}
Persistent excitation is key to parameter convergence and thereby provides robustness. What does PE provide in a closed loop? Since $u$ is dictaded by the control law, so PE must be provided by the reference signal $r$. \textbf{Thus, PE may be present in tracking problems, but rarely in set point regulation problems. And in these cases, lack of robustness is a significant problem if not dealt with somehow.}
\\\\
Consider the system
\begin{equation*}
	y = \theta^{*}u + d
\end{equation*}
where $d$ is a bounded known disturbance and $u \in \mathcal{L}_{\infty}$.
Assuming $d=0$, the adaptive law for estimationg the uncertain  parameter $\theta^{*}$ is
\begin{equation*}
	\dot \theta = \gamma \epsilon u, \qquad = \epsilon = y - \theta u
\end{equation*}
where $\gamma > 0$. Furthermore we can define the parameter error dynamics as
\begin{equation*}
	\dot{\tilde{\theta}} = - \gamma u^{2}\tilde{\theta}
\end{equation*}
when $d = 0$ and
\begin{equation*}
	i \dot{\tilde{\theta}} = - \gamma u^{2}\tilde{\theta} + \gamma d u
\end{equation*}
when $d \neq 0$. We establishes that $u, \dot{u}, \dot{\theta}, \theta, \epsilon  \in \mathcal{L}_\infty $. We can though find countless of example that disprove boundedness of $\theta$. This instability is known as parameter \textbf{parameter drift}. If $u$ is PE, then then $\theta$ is bounded. However, in adaptive control, the input $u$ is computed using a control law which may not provide PE, and it is of interest toguarantee stability and robustness in this case as well. This can be achived by modifying the adaptive laws we haev developed earlier.
\begin{equation}
	y=G_0(s) u+\Delta_u(s) u+\Delta_y(s) y+d
\end{equation}
where $G_0(s)$ is the dobinant part of the system, while $\Delta_u \text{ and } \Delta _y$ are strictly proper with stable poles representing unmodelled dynamics of the plant. $d$ is a bounded disturbance. We want to design adaptive laws for estimating the parameters in
\begin{equation}
	G_0(s)=\frac{Z(s)}{R(s)}=\frac{b_m s^m+\cdots+b_1 s b_0}{s^n+a_{n-1} s^{n-1}+\cdots+a_1 s+a_0}
	\label{eq:G0}
\end{equation}
The SPM model for (\ref{eq:G0}) is
\begin{equation}
	z=\theta^{*^T} \phi + \eta
\end{equation}
where
\begin{equation*}
	\begin{aligned}
		\theta^* & =\left[b_m, \ldots, b_0, a_{n-1}, \ldots, a_0\right]^T \in \mathcal{R}^{n+m+1},                                                         \\
		z        & =\frac{s^n}{\Lambda(s)} y                                                                                                               \\
		\phi     & =\left[\frac{s^m}{\Lambda(s)} u, \ldots, \frac{1}{\Lambda(s)} u,-\frac{s^{n-1}}{\Lambda(s)} y, \ldots,-\frac{1}{\Lambda(s)} y\right]^T, \\
		\eta     & =\Delta_u(s) \frac{R(s)}{\Lambda(s)} u+\Delta_y(s) \frac{R(s)}{\Lambda(s)} y+\frac{R(s)}{\Lambda(s)} d .
	\end{aligned}
\end{equation*}
We have no apriori assumption on the boundedness of $u$ and $y$, so we need to design a normalizing signal $m_s$ that achieves $\frac{\phi}{m_s}, \frac{\eta}{m_s} \in \mathcal{L}_{\infty}$. It can be proven (see IF 3.12.1 for some further details) that this is achieved by the dynamic normalization signal
$$
	\begin{aligned}
		m_s^2     & =1+\alpha_0 \phi^T \phi+\alpha_1 n_d                  \\
		\dot{n}_d & =-\delta_0 n_d+\delta_1\left(u^2+y^2\right), n_d(0)=0
	\end{aligned}
$$
where $\alpha_0, \alpha_1, \delta_0, \delta_1>0$ are design parameters The normalization is ass usual applied to the estimation error.
\subsection{$\sigma$ modification}
In this method we apply a small stabilizating feedback into the adaptive law,
\begin{equation}
	\dot{\theta}=\Gamma \varepsilon \phi-\underbrace{\sigma_l \Gamma\left(\theta-\theta_0\right)}_{\text {what does this term do? }}, \theta(0)=\theta_0
\end{equation}
where $\sigma _l \geq 0$ is a small design parameter.
\subsection*{Fixed $\sigma $ modification}
Assume first that $\sigma_l=\sigma$ where $\sigma>0$ is a constant. We have the following result (Theorem 3.12.1 in IF):
\begin{itemize}
	\item $\varepsilon, \varepsilon m_s, \theta, \dot{\theta} \in \mathcal{L}_{\infty}$.
	\item $\varepsilon, \varepsilon m_s, \dot{\theta} \in \mathcal{S}\left(\sigma+\frac{\eta^2}{m_s^2}\right)$.
	\item If $\frac{\phi}{m_s}$ is PE with level $\alpha_0>0$, then $\tilde{\theta}(t)$ converges exponentially to the residual set $D_\sigma=\{\tilde{\theta}:|\tilde{\theta}| \leq c(\sigma+\bar{\eta})\}$, where $\bar{\eta}=\sup _t \frac{|\eta(t)|}{m_s(t)}$ and $c>0$ is some constant.
\end{itemize}
Clearly, $x \in \mathcal{S}(0)$ implies that $x \in \mathcal{L}_2$. However, since the fixed sigma modification introduces a disturbance (of the order of $\sigma$ ) that is present even if the modelling error is not $(\eta=0)$, the ideal properties of the adaptive law are lost, as seen in bullet point 2 and 3 . A strategy to avoid this drawback, is to use the $\sigma$-modification only when the estimate drifts outside a known bound.
\subsection*{Switching $\sigma$ modification}
Suppose a bound that satisfies $\left|\theta^*-\theta_0\right| \leq M_0$ is available, where $\theta_0$ is our initial guess for $\theta^*$. Then, rather than selecting $\sigma_l=\sigma$ for some fixed $\sigma$, we can gradually turn on the modification as our estimate drifts away from the known bound. That is
$$
	\sigma_l(t)=\left\{\begin{array}{l}
		0 \text { if }\left|\theta(t)-\theta_0\right| \leq M_0,                                                                       \\
		\left(\frac{\left|\theta(t)-\theta_0\right|}{M_0}-1\right)^{q_0} \text { if } M_0<\left|\theta(t)-\theta_0\right| \leq 2 M_0, \\
		\sigma \text { if }\left|\theta(t)-\theta_0\right|>2 M_0,
	\end{array}\right.
$$
where $q_0 \geq 1$ is any finite integer. The following result holds in this case (Theorem 3.12.2 in IF):
\textbf{These methods are used to ensure that the parameter estimates remain bounded even if the input signal is not PE.}
\section{Model Reference Control for SISO Plants}
Consider the single-input-single-output plant
$$
	\begin{aligned}
		\dot{x}_p & =A_p x_p+B_p u_p, x_p(0)=x_0, \\
		y_p       & =C_p^T x_p
	\end{aligned}
$$
where $x_p \in \mathcal{R}^n, y_p, u_p \in \mathcal{R}$. A transfer-function model of (1)-(2) can be expressed as
$$
	\begin{aligned}
		y_p    & =G_p(s) u_p,                \\
		G_p(s) & =k_p \frac{Z_p(s)}{R_p(s)},
	\end{aligned}
$$
where $Z_p(s)$ is monic of order $m_p$ and $R_p(s)$ is monic of order $n_p$, and $k_p$ is a constant referred to as the high frequency gain. We assume $n_p>$ $m_p$, which is why (2) does not contain a term $D_p u_p$ (for simplicity).
Consider also the reference model
$$
	\begin{aligned}
		\dot{x}_m & =A_m x_m+B_m r, x_m(0)=x_{m_0}, \\
		y_m       & =C_m^T x_m
	\end{aligned}
$$
where $x_m \in \mathcal{R}^{p_m}, y_m, r \in \mathcal{R} . r$ is a reference signal that is assumed to be a bounded and piecewise continuous function of time. A transferfunction model of (5)-(6) can be expressed as
$$
	\begin{aligned}
		y_m    & =W_m(s) r                   \\
		W_m(s) & =k_m \frac{Z_m(s)}{R_m(s)},
	\end{aligned}
$$
\section{AAPC Schemes}
\subsection{Polynomial Approach}
Consider the SISO LTI plant
\begin{equation}
	y_p = G_p (s) u_p, \qquad G_p(s) = \frac{Z_p(s)}{R_p(s)}
	\label{eqn: Gp}
\end{equation}
where $G_p(s)$ is proper and $R_p(s)$ is a monic polynomial ($x^n+c_{n-1} x^{n-1}+\cdots+c_2 x^2+c_1 x+c_0$). \textbf{We want to choose $u_p$ so that the closed-loop poles are assigned to thiose of a given monic Hurwitz polynomial $\mathbf{A^{*}(s)}$, where this polynomial ischosen based on the closed-loop prpeformance requirements.} We have the following assumptions about the plant:\
\begin{enumerate}
	\item $R_p(s)$ is a monic polynomial whose degree $\mathbf{n}$ is known.
	\item $Z_p(s), R_p(s)$ are coprime, and degree $(Z_p) < 0$.
\end{enumerate}
We see that we allow $Z_p$ and $R_p$ to be non-Hurwitz. We can also extend the pole placement control (PPC) objective to include tracking, where $y_p$ is required to follow a ceraitn class of reference $y_m (y_m \in \mathcal{L}_\infty )$
\begin{equation}
	Q_m(s) y_m = 0
\end{equation}
where $Q_m(s)$ is known as the internal model f $y_m$, wit all roots $q$ in $\Re[s] \leq 0$. The internal model is assumed to satisfy
\begin{enumerate}
	\item $Q_m(s), Z_p(s)$ are coprime
\end{enumerate}
\begin{frm-ex}[Choosing $Q_m$ based on $y_m$]
If $y_m (t) = c + \sin (3 t)$ where $c$ is any constant, then $Q_m = \mathcal{L}\{c + sin(3t)\} = (s^{2}+9)$, and we add an integrator to get $Q_m = (s^{2}+9)s$.
\end{frm-ex}

The PPC objective with tracking can be stated as follows: Design the control input $u_p$ so that the closed-loop poles are the same as the roots of $A^*(s)=0$ and $y_p$ tracks the reference signal $y_m$. Since the coefficients of $G_p(s)$ are unknown, an adaptive control scheme is used to meet the control objective. The design of the APPC scheme is based on the CE approach where the unknown parameters in the control law, designed to meet the control objective in the known parameter case, are replaced with their online estimates generated by an adaptive law.
\subsubsection{Step 1. PPC for known parameters}
We consider the control law
\begin{equation}
	Q_m(s) L(s) u_p=-P(s)\left(y_p-y_m\right)
	\label{eqn: QmLupPypym}
\end{equation}
where $P(s)$ has the degree $q+n-1$ and $L(s)$ has the degree $n-1$, and are satisfies
\begin{equation}
	L(s) Q_m(s) R_p(s)+P(s) Z_p(s)=A^*(s)
	\label{eqn: LQmRpPZp}
\end{equation}
$L(s)$ and $P(s)$ can be computed by solving the algebraic equation
\begin{equation}
	S_l \beta_l=\alpha_l^*
	\label{eqn: SLbeta}
\end{equation}
where
\begin{equation*}
	\begin{split}
		\beta_l  & =\left[l_q^T, p^T\right]^T, \quad \alpha_l^*=[\underbrace{0, \ldots, 0}_q, \alpha^{* T}]^T,   \\
		l_q      & =[\underbrace{0, \ldots, 0}_q, 1, l^T]^T \in \mathcal{R}^{n+q},                               \\
		l        & =\left[l_{n-2}, l_{n-3}, \ldots, l_1, l_0\right]^T \in \mathcal{R}^{n-1},                     \\
		p        & =\left[p_{n+q-1}, p_{n+q-2}, \ldots, p_1, p_0\right]^T \in \mathcal{R}^{n+q},                 \\
		\alpha^* & =\left[a_{2 n+q-2}^*, a_{2 n+q-3}^*, \ldots, a_1^*, a_0^*\right]^T \in \mathcal{R}^{2 n+q-1},
	\end{split}
\end{equation*}
and $l_i, p_i, a_i^*$ are the coefficients of the polynomials
\begin{equation*}
	\resizebox{1.1\columnwidth}{!}{%
		$\begin{aligned}
				L(s)   & =s^{n-1}+l_{n-2} s^{n-2}+\cdots+l_1 s+l_0=s^{n-1}+l^T \alpha_{n-2}(s)                                    \\
				P(s)   & =p_{n+q-1} s^{n+q-1}+p_{n+q-2} s^{n+q-2}+\cdots+p_1 s+p_0=p^T \alpha_{n+q-1}(s)                          \\
				A^*(s) & =s^{2 n+q-1}+a_{2 n+q-2}^* s^{2 n+q-2}+\cdots+a_1^* s+a_0^*=s^{2 n+q-1}+\alpha^{* T} \alpha_{2 n+q-2}(s)
			\end{aligned}$%
	}
\end{equation*}
respectively, where $\alpha_i(s)=\left[s^i, s^{i-1}, \ldots, s, 1\right]^T$.
\\
Using (\ref{eqn: LQmRpPZp}) and (\ref{eqn: QmLupPypym}), the closed-loop plant is described by
\begin{equation}
	y_p=\frac{Z_p P}{A^*} y_m .
\end{equation}

Similarly, from the plant equation in (\ref{eqn: Gp}) and the control law in (\ref{eqn: QmLupPypym}) and (\ref{eqn: LQmRpPZp}), we obtain
\begin{equation}
	u_p=\frac{R_p P}{A^*} y_m .
\end{equation}
The control law (6.30) can be realized as
\begin{equation}
	u_p=-C(s)\left(y_p-y_m\right), \quad C(s)=\frac{P(s)}{Q_m(s) L(s)},
\end{equation}
using $n+q-1$ integrators. Since $L(s)$ is not necessarily Hurwitz, $C(s)$ may have poles in $\Re[s] \geq 0$, which is not desirable in practice. An alternative realization of (6.30) is obtained by rewriting (6.30) as
\begin{equation}
	\Lambda(s) u_p=\Lambda(s) u_p-Q_m(s) L(s) u_p-P(s)\left(y_p-y_m\right),
\end{equation}
where $\Lambda(s)$ is any monic Hurwitz polynomial of degree $n+q-1$. Filtering each side with $\frac{1}{\Lambda(s)}$, we obtain
\begin{equation}
	u_p=\frac{\Lambda-L Q_m}{\Lambda} u_p-\frac{P}{\Lambda}\left(y_p-y_m\right)
\end{equation}
The control law is implemented using $2(n+q-1)$ integrators to realize the proper stable transfer functions $\frac{\Lambda-L Q_m}{\Lambda}, \frac{P}{\Lambda}$.
\subsubsection{Step 2. Estimation of plant polynomial}
Step 2. Estimation of plant polynomials
Using (6.28) and the results of the Gradient method the following parametric model can be derived:
\begin{equation}
	z=\theta_p^{* T} \phi
\end{equation}
where
\begin{equation}
	\begin{gathered}
		z=\frac{s^n}{\Lambda_p(s)} y_p, \\
		\theta_p^*=\left[\theta_b^{* T}, \theta_a^{* T}\right]^T, \\
		\phi=\left[\frac{\alpha_{n-1}^T(s)}{\Lambda_p(s)} u_p,-\frac{\alpha_{n-1}^T(s)}{\Lambda_p(s)} y_p\right]^T, \\
		\alpha_{n-1}(s)=\left[s^{n-1}, \ldots, s, 1\right]^T, \\
		\theta_a^*=\left[a_{n-1}, \ldots, a_0\right]^T, \\
		\theta_b^*=\left[b_{n-1}, \ldots, b_0\right]^T,
	\end{gathered}
\end{equation}
and $\Lambda_p(s)$ is a monic Hurwitz polynomial. If the degree of $Z_p(s)$ is less than $n-1$, then some of the first elements of $\theta_b^*=\left[b_{n-1}, \ldots, b_0\right]^T$ will be equal to zero, and the dimension of the parametric model can be reduced. Using the results of Chapter 3, a wide class of adaptive laws can be designed to estimate $\theta_p^*$. As an example we consider the gradient algorithm
\begin{equation}
	\dot{\theta}_p=\Gamma \varepsilon \phi, \quad \varepsilon=\frac{z-\theta_p^T \phi}{m_s^2}, \quad m_s^2=1+\phi^T \phi,
\end{equation}
where $\Gamma=\Gamma^T>0$ is the adaptive gain and
\begin{equation}
	\theta_p=\left[\hat{b}_{n-1}, \ldots, \hat{b}_0, \hat{a}_{n-1}, \ldots, \hat{a}_0\right]^T
\end{equation}
are the estimated plant parameters which can be used to form the estimated plant polynomials
\begin{equation}
	\begin{aligned}
		 & \hat{R}_p(s, t)=s^n+\hat{a}_{n-1}(t) s^{n-1}+\cdots+\hat{a}_1(t) s+\hat{a}_0(t), \\
		 & \hat{Z}_p(s, t)=\hat{b}_{n-1}(t) s^{n-1}+\cdots+\hat{b}_1(t) s+\hat{b}_0(t),
	\end{aligned}
\end{equation}
of $R_p(s), Z_p(s)$, respectively, at each time $t$.
\subsubsection{Step 3. Adaptive control law}
Step 3. Adaptive control law The adaptive control law is obtained by replacing the unknown polynomials $L(s), P(s)$ with their online estimates $\hat{L}(s, t), \hat{P}(s, t)$ calculated at each frozen time ${ }^{12} t$ using the polynomial equation
\[
\hat{L}(s, t) \cdot Q_m(s) \cdot \hat{R}_p(s, t)+\hat{P}(s, t) \cdot \hat{Z}_p(s, t)=A^*(s)
\]
i.e., the control law is formed as
\[
u_p=\left(\Lambda(s)-\hat{L}(s, t) Q_m(s)\right) \frac{1}{\Lambda(s)} u_p-\hat{P}(s, t) \frac{1}{\Lambda(s)}\left(y_p-y_m\right)
\]



















\end{multicols*}
\end{document}